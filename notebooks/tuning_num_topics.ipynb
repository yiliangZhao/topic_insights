{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ae3920",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook will run a process to find out the best number of topics in terms of the highest coherence score. The coherence score is a measure of how similar the words that make up the topics are. A higher coherence score indicates that the topics are composed of words that are more similar to each other, hence the topics themselves are more interpretable and meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab444c3d-6844-448f-af15-bc24ce89cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhaoyiliang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/zhaoyiliang/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code executed in 2.709465980529785 seconds\n",
      "The code executed in 3632.189742088318 seconds\n",
      "Num Topics = 2  has Coherence Value of 0.4241\n",
      "Num Topics = 4  has Coherence Value of 0.4112\n",
      "Num Topics = 6  has Coherence Value of 0.3922\n",
      "Num Topics = 8  has Coherence Value of 0.3833\n",
      "Num Topics = 10  has Coherence Value of 0.3805\n",
      "Num Topics = 12  has Coherence Value of 0.4038\n",
      "Num Topics = 14  has Coherence Value of 0.3943\n",
      "Num Topics = 16  has Coherence Value of 0.3635\n",
      "Num Topics = 18  has Coherence Value of 0.3828\n",
      "Num Topics = 20  has Coherence Value of 0.3809\n",
      "Num Topics = 22  has Coherence Value of 0.3862\n",
      "Num Topics = 24  has Coherence Value of 0.3572\n",
      "Num Topics = 26  has Coherence Value of 0.372\n",
      "Num Topics = 28  has Coherence Value of 0.3866\n",
      "Num Topics = 30  has Coherence Value of 0.3867\n",
      "Num Topics = 32  has Coherence Value of 0.3897\n",
      "Num Topics = 34  has Coherence Value of 0.3754\n",
      "Num Topics = 36  has Coherence Value of 0.372\n",
      "Num Topics = 38  has Coherence Value of 0.3855\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "\n",
    "import pandas as pd\n",
    "# fine tuning to find the best number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "import time\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.add('also')\n",
    "stop.add('could')\n",
    "\n",
    "\n",
    "english_words = set(words.words())\n",
    "\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "df = pd.read_csv('all_filings_and_sections.csv')[['Section1', 'Section1A', 'Section7']]\n",
    "\n",
    "def clean(doc: str) -> str:\n",
    "    \"\"\"\n",
    "    This function cleans the input document by removing specific strings, \n",
    "    stop words, punctuation, non-English words, and lemmatizing the words.\n",
    "    \n",
    "    Parameters:\n",
    "    doc (str): The input document to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "    str: The cleaned document.\n",
    "    \"\"\"\n",
    "    # Check if the input is a string\n",
    "    if not isinstance(doc, str):\n",
    "        return None\n",
    "    \n",
    "    # Remove specific strings from the document\n",
    "    doc = doc.replace('Item 1.', '')\n",
    "    doc = doc.replace('Item 1A.', '')\n",
    "    doc = doc.replace('Item 7.', '')\n",
    "    \n",
    "    # Remove stop words from the document\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    \n",
    "    # Remove punctuation from the document\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    \n",
    "    # Keep only English words in the document\n",
    "    english = \" \".join(word for word in punc_free.split() if word in english_words)\n",
    "    \n",
    "    # Lemmatize the words in the document and remove words with length less than or equal to 3\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in english.split() if len(word) > 3)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "df['Section1_clean'] = df['Section1'].apply(clean)\n",
    "df['Section1A_clean'] = df['Section1A'].apply(clean)\n",
    "df['Section7_clean'] = df['Section7'].apply(clean)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "documents1, documents2, documents3 = df['Section1_clean'], df['Section1A_clean'], df['Section7_clean']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "doc_clean1 = [doc.split() for doc in documents1] \n",
    "doc_clean2 = [doc.split() for doc in documents2] \n",
    "doc_clean3 = [doc.split() for doc in documents3] \n",
    "\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"The code executed in {execution_time} seconds\")\n",
    "\n",
    "doc_clean = doc_clean1 + doc_clean2 + doc_clean3\n",
    "\n",
    "# Creating the term dictionary of our corpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "start_time = time.time()\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=doc_clean, start=2, limit=40, step=2)\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"The code executed in {execution_time} seconds\")\n",
    "\n",
    "# Print the coherence scores\n",
    "for m, cv in zip(range(2, 40, 2), coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
